\documentclass[12pt]{article}
\usepackage[utf8]{inputenc}
%\setlength{\itemsep}{0pt}
%\setlength{\parsep}{0pt}
%\setlength{\oddsidemargin}{-0.1in}
%\setlength{\evensidemargin}{-0.1in}
%\setlength{\textheight}{9in}
%\setlength{\textwidth}{6in}
\usepackage[margin=1in]{geometry}
\usepackage{graphics}
\usepackage{bm}
\usepackage{setspace}
\usepackage{verbatim}
\usepackage{apacite}
\bibliographystyle{apacite}


\doublespacing
\title{663 Final Project: NUTS Algorithm}
\author{Stephanie Brown, Liz Lorenzi, Jody Wortman}
\date{April 6, 2016}

\begin{document}

\maketitle


\section*{Abstract}
Our project aims to implement and explore the No-U-Turn Sampler (NUTS), an algorithm for adaptively setting path lengths in Hamiltonian Monte Carlo. Hamiltonian Monte Carlo (HMC) is an MCMC algorithm that uses first-order gradient information to enable faster convergence by avoiding the random walk behavior and sensitivity to correlated parameters.  Specifically, NUTS uses a recursive algorithm which eliminates the need to manually tune parameters for step size and number of steps.  We implement this algorithm and compare its posterior accuracy and computational efficiency to other MCMC methods, such as Metropolis-Hastings, Gibbs samplers, and Hamiltonian MCMC. We show examples of how the tuning parameters from HMC can result in poor posterior estimations, and how the NUTS recursive tuning results in similar or better estimation without the need for manual tuning. In addition, we implement the Efficient NUTS algorithm as well as the NUTS with Dual Averaging, to explore the speed ups available for this algorithm.


\section{Introduction}
In a growing field of Bayesian statistics and with the increasing use of Bayesian hierarchical models, valid methods for posterior estimation are critical. Because posterior distributions for some models are impossible to calculate analytically, researchers and analysts rely on Markov Chain Monte Carlo (MCMC) when tractable posteriors are unavailable. Commonly used MCMC methods are symmetric Metropolis algorithms and Gibbs samplers. Both of these methods are simple but can take so long to converge that they are not useful. While Hamiltonian Monte Carlo (HMC) addresses some of these issues via an approach that uses a set auxiliary variables, the approach necessitates user input of tuning parameters. Because performance is dependent on these parameters, HMC is not as widely used as it could be given its benefits. This issue is addressed by an algorithm called the No U-Turn Sampler (NUTS) proposed by Hoffman and Gelman \citeyear{homan2014no}. NUTS adaptively sets these parameters so that they do not require user input. \\
In this paper, we review the background of MCMC and HMC, motivating the adaptation. We then introduce NUTS and outline its advantages. We implement the algorithm in various stages of complexity and efficiency, compare it to other common MCMC methods, explore its strengths and weaknesses, and discuss its benefits to the Bayesian statistics community.
\subsection{MCMC}
MCMC methods simulate from a posterior distribution through drawing correlated samples--if the algorithm is correct and appropriate, these will converge to the target distribution \cite{neal}. These methods differ from each other--one common one is Gibbs sampling \cite{geman}, which updates conditional distributions until they all converge. However, this approach requires deriving the conditional distributions, which may not always be possible. Another approach is random walk Metropolis \cite{metropolis}, which uses likelihood ratios to either move to a new point in the posterior distribution or remain in the same place. Both methods may take a very long time to converge, however, as they both explore the parameter space in a stochastic, not necessarily efficient manner. 
\subsection{Hamiltonian Monte Carlo}
Hamiltonian Monte Carlo (HMC, also called Hybrid Monte Carlo) \cite{duane, neal} is a method which uses auxiliary variables in the Monte Carlo proposals. The method has a physical motivation, where each of the auxiliary variables $r_d$ correspond to the momentum of each model variable $\theta_d$. The algorithm uses direction and gradient information to update the values. Hoffman and Gelman outline a version of HMC in their paper where a leapfrog function is used to update $r$ and $\theta$ using the leapfrog integrator. The parameter proposals are then accepted or rejected using a Metropolis algorithm \cite{metropolis}. This method can work very well and converge faster than random walk Metropolis, but its degree of success is highly dependent on choosing both the step size $\epsilon$ and the number of steps $L$. Poor choices have varying consequences from inaccuracy to lack of convergence, but they generally lead to a slow but ergodic chain \cite{homan2014no}.

\subsection{NUTS Algorithm and Advantages}
Due to the issues caused by poor choices of $\epsilon$ and $L$ (though mostly $L$), Hoffman and Gelman's paper develops a method to adaptively select these parameters. The No-U-Turn Sampler eliminates the need for select the number of steps, and NUTS with dual averaging allows $\epsilon$ to also be adaptively set. The paper outlines the NUTS algorithm, then dual averaging. First, there is a naive approach, then an efficient version. We implement both and test their performance against each other and a standard Gibbs sampler and random walk Metropolis. 



\section{Implementation}
The python implementation of the NUTS algorithm involved first coding HMC then NUTS, and finally an efficient version of NUTS which will be discussed in detail in the Optimization section. Care was taken to use functions whenever possible in order to keep code readable and efficient.  Notation was kept consistent with that found in the original algorithm as written by Hoffman and Gelman.
\subsection{Hamiltonian Monte Carlo}
Hamiltonian Monte Carlo is a more basic version of our final algorithe, and therefore was where we started.  HMC also served as a time comparison. 

\subsection{Naive No-U-Turn Sampler}
The Naive NUTS algorithm improves upon HMC and no longer requires the user to specifity the L parameter.  Specification of epsilon is still needed.

\section{Optimization}
The aim of NUTS addresses key efficiency issues in the Hamiltonian Monte Carlo method. HMC is limited by its need of tuning of the step sizes ($\epsilon$) and number of steps($L$), typically needing multiple runs to find the correct parameter values. In addition, Hoffman and Gelman provide additional improvements in the NUTS algorithm to improve the efficiency. The first is Efficient No-U-Turn Sampler.
\subsection{Efficient No-U-Turn Sampler}
The original NUTS algorithm takes $2^j -1$ evaluations of the log likelihood and its gradient, where $j$ is the number of times we call BuildTree (see Appendix for more information on algorithms). In addition, there are $O(2^j)$ operations to determine when to stop doubling. When implemented, the most costly computational aspect of the original NUTS algorithm is the computation of the log joint distribution and its gradient. This results in an algorithm that has similar computational complexity to the original HMC. Another computationally costly aspect of the original NUTS is the storage of the $2^j$ position and momentum vectors, requiring a lot of memory.  Efficient NUTS aims to to solve these issues in the following ways. First, we change the transition kernel to produce larger jumps than the simple uniform sampling. This kernel has a memory-efficient implementation, reducing the number of position and momentum vectors stored to $O(j)$ instead of $O(2^j)$ Second, they aim to find a stopping criterion in the final doubling iteration to avoid wasting computation to build a set that won't be used. This is done by breaking out of the recursion when they encounter a zero for the stop indicator $s$.
  
\subsection{No-U-Turn Sampler with Dual Averaging}
NUTS and Efficient NUTS addresses the issue of choosing the number of Leapfrog steps, $L$. NUTS with Dual Averaging aims to take this a step further to also adaptively tuning $\epsilon$, the step size parameter. The Dual Averaging scheme is initially motivated by work of \cite{robbins} where they propose a vanishing adaptation algorithm for MCMC using stochastic approximation. 

...may be removing this section

\subsection{Implementing with Cython}
For further improvements, we look to the power of Python and its ability to compile python code to C. Specifically, we use the Cython capabilities to covert our working functions to C files for even further optimality. 

\section{Testing: Comparison to other MCMC methods}
\subsection{Posterior Estimation} 
\subsection{Efficiency}
\subsection{Comparison to Stan}

\section{Discussion}
\subsection{Review of Algorithm}
In this paper, we reviewed common approaches to MCMC, including Gibbs sampling, random walk Metropolis, and Hamiltonian Monte Carlo. We then introduced and implemented the No-U-Turn Sampler proposed by Hoffman and Gelman \citeyear{homan2014no}. We used a naive version and also an efficient version and tested both against the other methods. \\
A BIT ABOUT PERFORMANCE AND RESULTS\\
The NUTS algorithm has enormous potential for any research involving Bayesian models and posterior estimation of continuous distributions. It addresses the key setbacks of HMC (the need to specify step size and number of steps), and in doing so allows for more common use and implementation. Additionally, the authors created the package PyStan so that the algorithm can be more widely used by those who cannot or choose not to write the code themselves. While we used our own code in this paper, the availability of such a package arguably increases the value of the method, as it will be accessible beyond those with the ability to execute it independently. Overall, the algorithm is a useful and flexible tool that addresses a major limitation of HMC and MCMC generally.

\newpage
\bibliography{bibliograph.bib}
\end{document}

